{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e13d1833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import re\n",
    "from transformers import AutoTokenizer, DistilBertTokenizer, DistilBertForSequenceClassification, AutoModelForSequenceClassification, Trainer, TrainingArguments, DistilBertConfig\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import wordnet\n",
    "import random\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import nltk\n",
    "from transformers import DistilBertTokenizer\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd499ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "external documentation       501\n",
       "model structure              195\n",
       "project metadata             141\n",
       "sharing                      127\n",
       "preprocessing                 61\n",
       "training infrastructure       55\n",
       "validation infrastructure     52\n",
       "input data                    35\n",
       "internal documentation        35\n",
       "pipeline performance          33\n",
       "parameter tuning              31\n",
       "add dependency                19\n",
       "output data                   18\n",
       "update dependency             17\n",
       "remove dependency             15\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset/combined_GH_HF_manual.csv\")\n",
    "\n",
    "# Function to clean text columns\n",
    "def clean_text(text):\n",
    "    # Remove non-ASCII characters (corrupted/malformed characters)\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)  # Remove non-ASCII characters\n",
    "    return text.strip()\n",
    "\n",
    "# Apply cleaning function to relevant columns\n",
    "df['message'] = df['message'].apply(clean_text)\n",
    "df = df[df['message'].notna() & (df['message'] != '') & (df['message'].str.split().str.len() > 1)]\n",
    "df[\"label\"] = df[\"label\"].str.lower()\n",
    "\n",
    "number_of_labels = df[\"label\"].value_counts()\n",
    "number_of_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2f6482",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Step 1: Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(df[\"label\"])\n",
    "df['encoded_labels'] = label_encoder.fit_transform(df['label'])\n",
    "label_mapping = {index: label for index, label in enumerate(label_encoder.classes_)}\n",
    "print(label_mapping)\n",
    "\n",
    "# Step 2: Prepare texts and labels\n",
    "data_texts = df['message'].tolist()\n",
    "data_labels = df['encoded_labels'].tolist()\n",
    "\n",
    "# Step 3: Train/Val/Test Split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    data_texts, data_labels, test_size=0.2, random_state=0, shuffle=True\n",
    ")\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    train_texts, train_labels, test_size=0.01, random_state=0, shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"Training data: {len(train_texts)}\")\n",
    "print(f\"Validation data: {len(val_texts)}\")\n",
    "print(f\"Test data: {len(test_texts)}\")\n",
    "\n",
    "# Step 4: Initialize tokenizer\n",
    "model_name = \"sentence-transformers/paraphrase-MiniLM-L6-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Step 5: Tokenization function\n",
    "def preprocess_function(texts):\n",
    "    return tokenizer(\n",
    "        texts,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=64,  # optimized for short text\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "# Step 6: Tokenize datasets\n",
    "train_encodings = preprocess_function(train_texts)\n",
    "val_encodings = preprocess_function(val_texts)\n",
    "test_encodings = preprocess_function(test_texts)\n",
    "\n",
    "# Step 7: Wrap into dataset dicts\n",
    "train_dataset = [{\n",
    "    \"input_ids\": enc,\n",
    "    \"attention_mask\": train_encodings[\"attention_mask\"][i],\n",
    "    \"labels\": torch.tensor(train_labels[i])\n",
    "} for i, enc in enumerate(train_encodings[\"input_ids\"])]\n",
    "\n",
    "val_dataset = [{\n",
    "    \"input_ids\": enc,\n",
    "    \"attention_mask\": val_encodings[\"attention_mask\"][i],\n",
    "    \"labels\": torch.tensor(val_labels[i])\n",
    "} for i, enc in enumerate(val_encodings[\"input_ids\"])]\n",
    "\n",
    "test_dataset = [{\n",
    "    \"input_ids\": enc,\n",
    "    \"attention_mask\": test_encodings[\"attention_mask\"][i],\n",
    "    \"labels\": torch.tensor(test_labels[i])\n",
    "} for i, enc in enumerate(test_encodings[\"input_ids\"])]\n",
    "\n",
    "# Step 8: Check sample\n",
    "print(train_dataset[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
